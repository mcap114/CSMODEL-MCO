{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92be349",
   "metadata": {},
   "source": [
    "# CSMODEL Project - Netflix Userbase Dataset Case Study\n",
    "\n",
    "### Group 8\n",
    "CAPAROS, MIGUEL ANTONIO <br> \n",
    "FERRER, ANGEL JUNE <br>\n",
    "MARTINEZ, AZELIAH <br>\n",
    "VILLANUEVA, KEISHA LEIGH <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e871d42",
   "metadata": {},
   "source": [
    "# I. Dataset Description\n",
    "\n",
    "The Netflix Userbase Dataset provides a snapshot of a sample Netflix userbase, showcasing various aspects of user subscriptions, revenue, account details, and activity. Each row represents a unique user, identified by their User ID. The dataset serves as a synthetic representation and does not reflect actual Netflix user data. \n",
    "\n",
    "\n",
    "## Data Collection Process\n",
    "\n",
    "The dataset is synthetically sourced, and as such, any conclusions and insights may not accurately reflect real-world data. \n",
    "\n",
    "\n",
    "\n",
    "## Dataset File Structure\n",
    "\n",
    "Each row in the dataset represents a unique user. Each columns contain various details about the user. The dataset contains a total of 2500 observations (rows) and 10 variables (columns). Each variable provides specific details about the users, enabling analysis of subscription patterns, revenue generation, and user behavior.\n",
    "\n",
    "***If the dataset is composed of different files that you will combine in the succeeding steps, describe the structure and the contents of each file.***\n",
    "\n",
    "\n",
    "## Dataset Variables\n",
    "\n",
    "The dataset contains 10 variables, each representing different user information such as:\n",
    "\n",
    "- User ID: A unique identifier for each user.\n",
    "- Subscription Type: The type of subscription the user has (basic, standard, or premium).\n",
    "- Monthly Revenue: The monthly revenue generated from the user's subscription.\n",
    "- Join Date: The date the user joined Netflix.\n",
    "- Last Payment Date: The date of the user's last payment.\n",
    "- Country: The country where the user is located.\n",
    "- Age: The age of the user.\n",
    "- Gender: The gender of the user.\n",
    "- Device Type: The type of device the user primarily uses to access Netflix (e.g., Smart TV, Mobile, Desktop, Tablet).\n",
    "- Plan Duration: The duration of the user's current subscription plan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e920be",
   "metadata": {},
   "source": [
    "# II. Data Cleaning\n",
    "\n",
    "In this section of the notebook, we will focus on cleaning the Netflix Userbase Dataset. Data cleaning is an essential step in the data analysis process, aimed at preparing raw data for further exploration and analysis. It involves identifying and correcting errors or inconsistencies in the data, handling missing values, removing duplicates, and ensuring data quality and integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fed12",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We begin by importing **`numpy`** and **`pandas`** which are essential libraries for data manipulation and analysis in Python to begin our data cleaning process.\n",
    "\n",
    "**`numpy`** is a fundamental package for numerical computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. [**`pandas`**](https://pandas.pydata.org/pandas-docs/stable/index.html) is a Python software library that offers data structures and tools for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "051b3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d88c0f",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a8d85",
   "metadata": {},
   "source": [
    "Insert description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f73be4",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "\n",
    "Our first step is to load the dataset using pandas, which will import the data into a pandas `DataFrame`. We use the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3aad751",
   "metadata": {},
   "outputs": [],
   "source": [
    "userbase_df = pd.read_csv('Netflix Userbase.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22031596",
   "metadata": {},
   "source": [
    "When loading a new dataset, it is advisable to utilize the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function, as it displays general information regarding the dataset's structure and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db605c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   User ID            2500 non-null   int64 \n",
      " 1   Subscription Type  2500 non-null   object\n",
      " 2   Monthly Revenue    2500 non-null   int64 \n",
      " 3   Join Date          2500 non-null   object\n",
      " 4   Last Payment Date  2500 non-null   object\n",
      " 5   Country            2500 non-null   object\n",
      " 6   Age                2500 non-null   int64 \n",
      " 7   Gender             2500 non-null   object\n",
      " 8   Device             2500 non-null   object\n",
      " 9   Plan Duration      2500 non-null   object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "userbase_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482093d4",
   "metadata": {},
   "source": [
    "We will use the [`head`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) function to quickly view the first few rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b70a76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Monthly Revenue</th>\n",
       "      <th>Join Date</th>\n",
       "      <th>Last Payment Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Device</th>\n",
       "      <th>Plan Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Basic</td>\n",
       "      <td>10</td>\n",
       "      <td>15-01-22</td>\n",
       "      <td>10-06-23</td>\n",
       "      <td>United States</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>1 Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Premium</td>\n",
       "      <td>15</td>\n",
       "      <td>05-09-21</td>\n",
       "      <td>22-06-23</td>\n",
       "      <td>Canada</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>1 Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Standard</td>\n",
       "      <td>12</td>\n",
       "      <td>28-02-23</td>\n",
       "      <td>27-06-23</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Smart TV</td>\n",
       "      <td>1 Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Standard</td>\n",
       "      <td>12</td>\n",
       "      <td>10-07-22</td>\n",
       "      <td>26-06-23</td>\n",
       "      <td>Australia</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>1 Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Basic</td>\n",
       "      <td>10</td>\n",
       "      <td>01-05-23</td>\n",
       "      <td>28-06-23</td>\n",
       "      <td>Germany</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Smartphone</td>\n",
       "      <td>1 Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID Subscription Type  Monthly Revenue Join Date Last Payment Date  \\\n",
       "0        1             Basic               10  15-01-22          10-06-23   \n",
       "1        2           Premium               15  05-09-21          22-06-23   \n",
       "2        3          Standard               12  28-02-23          27-06-23   \n",
       "3        4          Standard               12  10-07-22          26-06-23   \n",
       "4        5             Basic               10  01-05-23          28-06-23   \n",
       "\n",
       "          Country  Age  Gender      Device Plan Duration  \n",
       "0   United States   28    Male  Smartphone       1 Month  \n",
       "1          Canada   35  Female      Tablet       1 Month  \n",
       "2  United Kingdom   42    Male    Smart TV       1 Month  \n",
       "3       Australia   51  Female      Laptop       1 Month  \n",
       "4         Germany   33    Male  Smartphone       1 Month  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userbase_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244c015",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171e0b3",
   "metadata": {},
   "source": [
    "Detecting and managing missing values is crucial for data analysis. To identify missing data within our DataFrame, we will use the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) function in combination with [`sum`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html). This approach allows us to understand the extent of missing values in each column, facilitating appropriate strategies for data cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9530fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data:\n",
      " User ID              0\n",
      "Subscription Type    0\n",
      "Monthly Revenue      0\n",
      "Join Date            0\n",
      "Last Payment Date    0\n",
      "Country              0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Device               0\n",
      "Plan Duration        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = userbase_df.isnull().sum()\n",
    "print(\"Missing data:\\n\", missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a8c65",
   "metadata": {},
   "source": [
    "## Outlier Handling\n",
    "\n",
    "Insert description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbd664",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Insert description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0ea9b",
   "metadata": {},
   "source": [
    "## Duplicate Handling\n",
    "\n",
    "Duplicates in datasets can impact the accuracy of analysis results and should be managed to ensure data integrity. Identifying and managing duplicates is an essential step in data preprocessing. We use the [`duplicated`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html) function to find rows that are exact duplicates based on specified columns (`subset`). For instance, we will check for duplicates based on 'Country' and 'Subscription Type'. If duplicates are identified (`not duplicate_rows.empty`), they are displayed for further examination. Otherwise, a message indicating no duplicates are found is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a7daf",
   "metadata": {},
   "source": [
    "This code snippet identifies and prints duplicate rows in the dataset that have the same values in the 'Country' column. The `duplicated()` function with `keep=False` ensures all occurrences of duplicates are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57154859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows based on 'Country':\n",
      "      User ID Subscription Type  Monthly Revenue Join Date Last Payment Date  \\\n",
      "0           1             Basic               10  15-01-22          10-06-23   \n",
      "1           2           Premium               15  05-09-21          22-06-23   \n",
      "2           3          Standard               12  28-02-23          27-06-23   \n",
      "3           4          Standard               12  10-07-22          26-06-23   \n",
      "4           5             Basic               10  01-05-23          28-06-23   \n",
      "...       ...               ...              ...       ...               ...   \n",
      "2495     2496           Premium               14  25-07-22          12-07-23   \n",
      "2496     2497             Basic               15  04-08-22          14-07-23   \n",
      "2497     2498          Standard               12  09-08-22          15-07-23   \n",
      "2498     2499          Standard               13  12-08-22          12-07-23   \n",
      "2499     2500             Basic               15  13-08-22          12-07-23   \n",
      "\n",
      "             Country  Age  Gender      Device Plan Duration  \n",
      "0      United States   28    Male  Smartphone       1 Month  \n",
      "1             Canada   35  Female      Tablet       1 Month  \n",
      "2     United Kingdom   42    Male    Smart TV       1 Month  \n",
      "3          Australia   51  Female      Laptop       1 Month  \n",
      "4            Germany   33    Male  Smartphone       1 Month  \n",
      "...              ...  ...     ...         ...           ...  \n",
      "2495           Spain   28  Female    Smart TV       1 Month  \n",
      "2496           Spain   33  Female    Smart TV       1 Month  \n",
      "2497   United States   38    Male      Laptop       1 Month  \n",
      "2498          Canada   48  Female      Tablet       1 Month  \n",
      "2499   United States   35  Female    Smart TV       1 Month  \n",
      "\n",
      "[2500 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = userbase_df[userbase_df.duplicated(subset='Country', keep=False)]\n",
    "\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows based on 'Country':\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found based on 'Country'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ee8b0",
   "metadata": {},
   "source": [
    "Similarly, this code checks for duplicates based on the 'Subscription Type' column. It provides a clear indication of whether duplicate records exist in the dataset related to subscription types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527cda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows based on 'Subscription Type':\n",
      "      User ID Subscription Type  Monthly Revenue Join Date Last Payment Date  \\\n",
      "0           1             Basic               10  15-01-22          10-06-23   \n",
      "1           2           Premium               15  05-09-21          22-06-23   \n",
      "2           3          Standard               12  28-02-23          27-06-23   \n",
      "3           4          Standard               12  10-07-22          26-06-23   \n",
      "4           5             Basic               10  01-05-23          28-06-23   \n",
      "...       ...               ...              ...       ...               ...   \n",
      "2495     2496           Premium               14  25-07-22          12-07-23   \n",
      "2496     2497             Basic               15  04-08-22          14-07-23   \n",
      "2497     2498          Standard               12  09-08-22          15-07-23   \n",
      "2498     2499          Standard               13  12-08-22          12-07-23   \n",
      "2499     2500             Basic               15  13-08-22          12-07-23   \n",
      "\n",
      "             Country  Age  Gender      Device Plan Duration  \n",
      "0      United States   28    Male  Smartphone       1 Month  \n",
      "1             Canada   35  Female      Tablet       1 Month  \n",
      "2     United Kingdom   42    Male    Smart TV       1 Month  \n",
      "3          Australia   51  Female      Laptop       1 Month  \n",
      "4            Germany   33    Male  Smartphone       1 Month  \n",
      "...              ...  ...     ...         ...           ...  \n",
      "2495           Spain   28  Female    Smart TV       1 Month  \n",
      "2496           Spain   33  Female    Smart TV       1 Month  \n",
      "2497   United States   38    Male      Laptop       1 Month  \n",
      "2498          Canada   48  Female      Tablet       1 Month  \n",
      "2499   United States   35  Female    Smart TV       1 Month  \n",
      "\n",
      "[2500 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = userbase_df[userbase_df.duplicated(subset='Subscription Type', keep=False)]\n",
    "\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows based on 'Subscription Type':\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found based on 'Subscription Type'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98517c8",
   "metadata": {},
   "source": [
    "## Handling Inconsistent Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c462a3",
   "metadata": {},
   "source": [
    "Inconsistent formatting in a dataset can cause errors in analysis and lead to misinterpreted results. Different representations of the same data, such as variations in text case ('United States', 'united States', 'UNITED STATES') or inconsistent date formats, can be mistakenly treated as different values. This can distort analysis outcomes and produce inaccurate conclusions. By standardizing data formats, we ensure uniformity, which allows for accurate comparisons and aggregations. This consistency is essential for reliable data analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237f88e",
   "metadata": {},
   "source": [
    "To address this, let's standardize the 'Country' and 'Subscription Type' columns to lowercase. Using [`str.lower`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html) function, it converts all entries in the 'Country' and 'Subscription Type' columns to lowercase, ensuring consistency. The [`unique`](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html) function is then used to display all unique values in the column after the transformation, allowing us to verify that the standardization was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ac84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values after converting 'Country' to lowercase:\n",
      "['united states' 'canada' 'united kingdom' 'australia' 'germany' 'france'\n",
      " 'brazil' 'mexico' 'spain' 'italy']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userbase_df['Country'] = userbase_df['Country'].str.lower()\n",
    "\n",
    "print(\"Unique values after converting 'Country' to lowercase:\")\n",
    "print(userbase_df['Country'].unique())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f325eb",
   "metadata": {},
   "source": [
    "Convert all subsription types to lowercase for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "803874d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values after converting 'Subscription Type' to lowercase:\n",
      "['basic' 'premium' 'standard']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userbase_df['Subscription Type'] = userbase_df['Subscription Type'].str.lower()\n",
    "\n",
    "print(\"Unique values after converting 'Subscription Type' to lowercase:\")\n",
    "print(userbase_df['Subscription Type'].unique())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266584b",
   "metadata": {},
   "source": [
    "# III. Exploratory Data Analysis\n",
    "\n",
    "In this section of the notebook, we aim to explore and understand various aspects of the Netflix Userbase Dataset through exploratory data analysis. We will address the following questions:\n",
    "\n",
    "1. **Subscription Description**\n",
    "\n",
    "\n",
    "   *Question: What is the distribution of users across different subscription types?*\n",
    "\n",
    "\n",
    "\n",
    "2. **Revenue Analysis**\n",
    "\n",
    "\n",
    "   *Question: How much revenue is generated from each subscription type?*\n",
    "\n",
    "\n",
    "3. **User Retention**\n",
    "\n",
    "\n",
    "   *Question:*\n",
    "\n",
    "\n",
    "4. **Device Type Usage**\n",
    "\n",
    "\n",
    "   *Question: What is the distribution of device types used by Netflix users?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244fa11",
   "metadata": {},
   "source": [
    "# IV. Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f427d",
   "metadata": {},
   "source": [
    "The research question drives the focus of our data analysis project and should emerge from insights gained during exploratory data analysis (EDA).\n",
    "\n",
    "- **Are there any patterns in subscription type preferences based on country?**\n",
    "\n",
    "This research question examines whether distinct patterns exist in Netflix subscription type preferences (Basic, Standard, Premium) across different countries. Understanding these patterns is crucial for Netflix to tailor its content offerings and subscription plans according to regional preferences, potentially improving user satisfaction and retention. By uncovering significant insights from exploratory data analysis (EDA) of the Netflix userbase dataset, this study aims to provide actionable recommendations for strategic decision-making in global market expansion and customer engagement strategies. Through this analysis, we seek to reveal regional trends in subscription choices, offering valuable insights into user behavior across diverse countries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
